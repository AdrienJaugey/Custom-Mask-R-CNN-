{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dto-uOuWSZIE"
   },
   "source": [
    "# Updated Mask R-CNN - Train cell nucleus Dataset\n",
    "This is an updated version of [Mask R-CNN - Train cell nucleus Dataset](https://colab.research.google.com/github/navidyou/Mask-RCNN-implementation-for-cell-nucleus-detection-executable-on-google-colab-/blob/master/mask_RCNN_cell_nucleus_google_colab.ipynb) for Google Colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hy5xg58-3p-"
   },
   "source": [
    "## Initialisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the main variables to customize the training. Be sure to set the number of epoch you want along with the correct weights file to use as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to which epoch it should train\n",
    "NB_EPOCHS = 1\n",
    "\n",
    "# To restart or continue training, set to last\n",
    "# If custom is choosed, please set custom_weights_file to true name of the file (should be in ./logs/ directory)\n",
    "init_with = \"base\" #@param [\"coco\", \"imagenet\", \"last\", \"base\", \"custom\"]\n",
    "custom_weights_file = \"mask_rcnn_nephrologie_XXX_XXX.h5\"\n",
    "\n",
    "# Format of images in the dataset (if wrapper used, it should be png)\n",
    "IMAGE_FORMAT = 'png' #@param ['jp2', 'png', 'jpg', 'bmp']\n",
    "# Side size of a division\n",
    "DIVISION_SIZE = 1024\n",
    "\n",
    "# For main training, set cortexMode to false\n",
    "# Remaining of test about cortex detection, should be deleted or replaced\n",
    "cortexMode = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "EMwapxaFSZIH",
    "outputId": "6d7713da-1aa9-408a-fd55-b23e987f06a6",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import os\n",
    "    import sys\n",
    "    import random\n",
    "    import math\n",
    "    import re\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import json\n",
    "    #import pandas as pd\n",
    "    from shlex import quote\n",
    "    from time import time, ctime\n",
    "\n",
    "    TOAST = True\n",
    "    if TOAST:\n",
    "        try:\n",
    "            from win10toast import ToastNotifier\n",
    "            toaster = ToastNotifier()\n",
    "        except:\n",
    "            TOAST = False\n",
    "\n",
    "    from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    classesInfo = [\n",
    "        {\"inferenceID\": 1, \"id\": 0,  \"name\": \"cortex\",            \"color\": \"#ffaa00\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 2, \"id\": 1,  \"name\": \"medullaire\",        \"color\": \"#ff0000\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 3, \"id\": 2,  \"name\": \"fond\",              \"color\": \"#ffffff\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 1, \"id\": 3,  \"name\": \"tubule_sain\",       \"color\": \"#ff007f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 2, \"id\": 4,  \"name\": \"tubule_atrophique\", \"color\": \"#55557f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 3, \"id\": 5,  \"name\": \"nsg_complet\",       \"color\": \"#ff557f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 4, \"id\": 6,  \"name\": \"nsg_partiel\",       \"color\": \"#55aa7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 5, \"id\": 7,  \"name\": \"pac\",               \"color\": \"#ffaa7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 6, \"id\": 8,  \"name\": \"vaisseau\",          \"color\": \"#55ff7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 7, \"id\": 9,  \"name\": \"artefact\",          \"color\": \"#000000\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 8, \"id\": 10, \"name\": \"veine\",             \"color\": \"#0000ff\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 9, \"id\": 11, \"name\": \"nsg\",               \"color\": \"#55007f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 1, \"id\": 12, \"name\": \"intima\",            \"color\": \"#aa0000\", \"ignore\": True},\n",
    "        {\"inferenceID\": 2, \"id\": 13, \"name\": \"media\",             \"color\": \"#aa5500\", \"ignore\": True}\n",
    "    ]\n",
    "    \n",
    "    # Data Path\n",
    "    if cortexMode:\n",
    "        TRAIN_PATH = 'nephrology_cortex_dataset_train/'\n",
    "        MAP_PATH = 'nephrology_cortex_dataset_val/'\n",
    "    else:\n",
    "        TRAIN_PATH = 'nephrology_dataset_train/'\n",
    "        MAP_PATH = 'nephrology_dataset_val/'\n",
    "    # Get train and test IDs\n",
    "    train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "    map_ids = next(os.walk(MAP_PATH))[1]\n",
    "\n",
    "    NB_STEPS = len(train_ids)\n",
    "    \n",
    "    CELLS_CLASS_NAMES = []\n",
    "    for classInfo in classesInfo:\n",
    "        if not classInfo[\"ignore\"]:\n",
    "            CELLS_CLASS_NAMES.append(classInfo[\"name\"])\n",
    "    NB_CLASS = len(CELLS_CLASS_NAMES)\n",
    "    COLOR_PER_CLASS = True\n",
    "    evaluation_size = len(map_ids)\n",
    "    # evaluation_size = 30 #@param {type:\"slider\", min:10, max:65, step:1}\n",
    "\n",
    "\n",
    "    from mrcnn import config\n",
    "    from mrcnn import utils\n",
    "    from mrcnn import model\n",
    "    from mrcnn import visualize\n",
    "\n",
    "    from mrcnn.config import Config\n",
    "    from mrcnn import utils\n",
    "    from mrcnn import model as modellib\n",
    "    from mrcnn import visualize\n",
    "    from mrcnn.model import log\n",
    "\n",
    "    %matplotlib inline \n",
    "\n",
    "    # Root directory of the project\n",
    "    ROOT_DIR = os.getcwd()\n",
    "\n",
    "    # Directories to save logs and trained model\n",
    "    MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    IMAGES_DIR = os.path.join(MODEL_DIR, \"images\")\n",
    "    if not os.path.exists(IMAGES_DIR):\n",
    "        os.makedirs(IMAGES_DIR)\n",
    "    CONF_MATRIX_DIR = os.path.join(MODEL_DIR, \"confusion_matrix\")\n",
    "    if not os.path.exists(CONF_MATRIX_DIR):\n",
    "        os.makedirs(CONF_MATRIX_DIR)\n",
    "    RESULT_CSV_PATH = os.path.join(MODEL_DIR, \"auto_results.csv\")\n",
    "    if not os.path.exists(RESULT_CSV_PATH):\n",
    "        with open(RESULT_CSV_PATH, 'w') as csv:\n",
    "            csv.write(\"datetime; input_weights; output_weights; nb_steps; nb_epochs; duration; mAP\")\n",
    "\n",
    "    # Local path to trained weights file\n",
    "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "    # Download COCO trained weights from Releases if needed\n",
    "    if not os.path.exists(COCO_MODEL_PATH):\n",
    "        utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "    print(\"Cell done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpT9HgC7SZIN"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "colab_type": "code",
    "id": "jBONWUhASZIO",
    "outputId": "30b3f0fb-e933-4b7c-b6e8-1fa2898a117c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class CellsConfig(Config):\n",
    "    \"\"\"Configuration for training on the dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"cells\"\n",
    "\n",
    "    # Train on 1 GPU and 1 images per GPU. We can put multiple images on each\n",
    "    # GPU. Batch size is (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + NB_CLASS  # background + all classes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = DIVISION_SIZE\n",
    "    IMAGE_MAX_DIM = DIVISION_SIZE\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 64, 128, 256)  # anchor side in pixels\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 800\n",
    "\n",
    "    # set number of epoch\n",
    "    STEPS_PER_EPOCH = NB_STEPS\n",
    "\n",
    "    # set validation steps\n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "\n",
    "config = CellsConfig()\n",
    "# config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dhvNUELSZIS"
   },
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj3zh7wMSZIW",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    #fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    #return ax\n",
    "    return plt.subplots(rows, cols, figsize=(size*cols, size*rows), frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjEu-7I1SZIY"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqkR3-OHSZIY",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class CellsDataset(utils.Dataset):\n",
    "    __CELLS_CLASS_NAMES = CELLS_CLASS_NAMES.copy()\n",
    "    mode = \"\"\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.__CELLS_CLASS_NAMES.copy()\n",
    "\n",
    "    def load_cells(self, mode):\n",
    "        # Add classes\n",
    "        for class_id, class_name in enumerate(self.__CELLS_CLASS_NAMES):\n",
    "            self.add_class(\"cells\", class_id + 1, class_name)\n",
    "\n",
    "        self.mode = mode\n",
    "        if self.mode == \"train\":\n",
    "            for n, id_ in enumerate(train_ids):\n",
    "                path = TRAIN_PATH + id_\n",
    "                img_path = path + '/images/'\n",
    "                self.add_image(\"cells\", image_id=id_, path=img_path)\n",
    "\n",
    "        if self.mode == \"val\":\n",
    "            for n, id_ in enumerate(map_ids):\n",
    "                path = MAP_PATH + id_\n",
    "                img_path = path + '/images/'\n",
    "                self.add_image(\"cells\", image_id=id_, path=img_path)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "        info = info.get(\"id\")\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            path = TRAIN_PATH + info\n",
    "        else:\n",
    "            path = MAP_PATH + info\n",
    "        img = imread(path + '/images/' + info + '.' + IMAGE_FORMAT)[:, :, :3]\n",
    "        img = resize(img, (config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]), mode='constant', preserve_range=True)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the cells data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"cells\":\n",
    "            return info[\"cells\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for cells of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        info = info.get(\"id\")\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            path = TRAIN_PATH + info\n",
    "        else:\n",
    "            path = MAP_PATH + info\n",
    "\n",
    "        # Counting masks for current image\n",
    "        number_of_masks = 0\n",
    "        for masks_dir in os.listdir(path):\n",
    "            # For each directory excepting /images\n",
    "            if masks_dir not in self.__CELLS_CLASS_NAMES:\n",
    "                continue\n",
    "            temp_DIR = path + '/' + masks_dir\n",
    "            # Adding length of directory https://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python\n",
    "            number_of_masks += len(\n",
    "                [name for name in os.listdir(temp_DIR) if os.path.isfile(os.path.join(temp_DIR, name))])\n",
    "\n",
    "        mask = np.zeros([config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], number_of_masks], dtype=np.uint8)\n",
    "        iterator = 0\n",
    "        class_ids = np.zeros((number_of_masks,), dtype=int)\n",
    "        for masks_dir in os.listdir(path):\n",
    "            if masks_dir not in self.__CELLS_CLASS_NAMES:\n",
    "                continue\n",
    "            temp_class_id = self.__CELLS_CLASS_NAMES.index(masks_dir) + 1\n",
    "            for mask_file in next(os.walk(path + '/' + masks_dir + '/'))[2]:\n",
    "                mask_ = imread(path + '/' + masks_dir + '/' + mask_file)\n",
    "                mask_ = resize(mask_, (config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]), mode='constant',\n",
    "                               preserve_range=True)\n",
    "                mask[:, :, iterator] = mask_\n",
    "                class_ids[iterator] = temp_class_id\n",
    "                iterator += 1\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(number_of_masks - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        return mask, class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6vXiPQepxhll",
    "outputId": "5e69c6fa-c483-4a04-9436-afcbf9844387",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "'''dataset_test = CellsDataset()\n",
    "dataset_test.load_cells('train')\n",
    "dataset_test.prepare()\n",
    "dataset_test.load_mask(0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAhNtW_TSZIb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = CellsDataset()\n",
    "dataset_train.load_cells(\"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CellsDataset()\n",
    "dataset_val.load_cells(\"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "yAizzQC5SZIf",
    "outputId": "215f6df3-955f-4086-b531-df717e6f682b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyEQKAnMSZIi"
   },
   "source": [
    "## Ceate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GCYogpmSZIj",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUuC-fI4SZIl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                                               \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    listDir = os.listdir(MODEL_DIR)\n",
    "    listDir.sort()\n",
    "    lastDir = ''\n",
    "    for logDir in listDir:\n",
    "        if os.path.isdir(os.path.join(MODEL_DIR, logDir)) and 'cells20' in logDir:\n",
    "            lastDir = logDir\n",
    "    lastDirPath = os.path.join(MODEL_DIR, lastDir)\n",
    "    listDir = os.listdir(lastDirPath)\n",
    "    listDir.sort()\n",
    "    lastFile = ''\n",
    "    for logFile in listDir:\n",
    "        if '.h5' in logFile:\n",
    "            lastFile = logFile\n",
    "    if lastFile == '':\n",
    "        print(\"Last file not found, using base\")\n",
    "        init_with = \"base\"\n",
    "        weights_path = os.path.join(MODEL_DIR, 'mask_rcnn_base.h5')\n",
    "    else:\n",
    "        weights_path = os.path.join(lastDirPath, lastFile)\n",
    "        print(\"Last file is \" + weights_path)\n",
    "    model.load_weights(weights_path, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"base\":\n",
    "    weights_path = os.path.join(MODEL_DIR, 'mask_rcnn_base.h5')\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                                            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"custom\":\n",
    "    weights_path = os.path.join(MODEL_DIR, custom_weights_file)\n",
    "    print(\"Loading {} as weights file\".format(weights_path))\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                                            \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzZuQxylSZIo"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0_mousFNZb9"
   },
   "source": [
    "### Starting to train\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN\",\n",
    "                       \"Starting training ({} steps, {} epochs)\".format(NB_STEPS, NB_EPOCHS),\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)\n",
    "start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "colab_type": "code",
    "id": "j2jmfqdLSZIp",
    "outputId": "615119d9-3b0f-45c0-b0e9-9cc64cca9e35",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=NB_EPOCHS, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wN1l921SZIt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "'''model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "training_time = round(time() - start_time)\n",
    "if TOAST:\n",
    "    h = ('0' if training_time // 3600 < 10 else '') + str(training_time // 3600)\n",
    "    m = ('0' if (training_time % 3600) // 60 < 10 else '') + str((training_time % 3600) // 60)\n",
    "    s = ('0' if training_time % 60 < 10 else '') + str(training_time % 60)\n",
    "    toaster.show_toast(\"Mask R-CNN\",\n",
    "                       \"Finish training ({} steps, {} epochs) in {}:{}:{}\".format(NB_STEPS, NB_EPOCHS, h, m, s),\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRK53lnTSZIx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "weights_saved_file = \"mask_rcnn_nephrologie{}_{}_{}.h5\".format(\"_cortex\" if cortexMode else \"\", NB_STEPS, NB_EPOCHS)\n",
    "model_path = os.path.join(MODEL_DIR, weights_saved_file)\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldulTQXRSZI0"
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGXrGMjVDBOt"
   },
   "source": [
    "### Initialisation of the inference model and loading of weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWhUidKESZI1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(CellsConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "if model_path is None or not os.path.exists(model_path):\n",
    "    model_path = os.path.join(MODEL_DIR, weights_saved_file)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Aw-MI01DRdc"
   },
   "source": [
    "### Inference on random selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSldvjKYDq8j"
   },
   "source": [
    "Display of randomly chosen image with exepected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-aJVKAhSZI3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                                                                   image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "_ = visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, dataset_train.class_names, \n",
    "                                colorPerClass=COLOR_PER_CLASS, figsize=(16, 16), \n",
    "                                title=\"{} Expected\".format(map_ids[image_id]), \n",
    "                                fileName=\"logs/images/[{}_{}] Expected\".format(NB_STEPS, NB_EPOCHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgSVf-PuDyl7"
   },
   "source": [
    "Detection and display of the predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyAT1glESZI7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "fig_, ax_ = get_ax(size=16)\n",
    "_ = visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], dataset_val.class_names, \n",
    "                                r['scores'], colorPerClass=COLOR_PER_CLASS, figsize=(16, 16), ax=ax_, fig=fig_, \n",
    "                                title=\"{} Predicted\".format(map_ids[image_id]), \n",
    "                                fileName=\"logs/images/[{}_{}] Predicted\".format(NB_STEPS, NB_EPOCHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8mN9BsDSZI-"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr8rCnaXJa7Q"
   },
   "source": [
    "### Mean Average Precision (mAP) computation on a multiple-detection test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ib5pJXg3SZJA",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "#Running on 30 images by default. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, evaluation_size)\n",
    "image_ids = dataset_val.image_ids\n",
    "random.shuffle(image_ids)\n",
    "APs = []\n",
    "confusion_matrix = np.zeros((NB_CLASS + 1, NB_CLASS + 1), \n",
    "                            dtype=np.int32)\n",
    "iterator = 1\n",
    "map_time = time()\n",
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN\",\n",
    "                       \"Starting mAP computation\",\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)\n",
    "for image_id in image_ids:\n",
    "    if TOAST and iterator == evaluation_size // 2:\n",
    "        toaster.show_toast(\"Mask R-CNN\", \"50% mAP computation achieved\",\n",
    "                           icon_path=None, duration=10, threaded=True)\n",
    "    start_time = time()\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, \n",
    "                                                       inference_config),\n",
    "                                   0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps, temp_confusion_matrix = \\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"],\n",
    "                             r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
    "                             nb_class=NB_CLASS, \n",
    "                             confusion_iou_threshold=0.1)\n",
    "    APs.append(AP)\n",
    "    confusion_matrix = np.add(confusion_matrix, temp_confusion_matrix)\n",
    "    duration = time() - start_time\n",
    "    minu = int(duration / 60)\n",
    "    sec = int(duration % 60)\n",
    "    iterator += 1\n",
    "\n",
    "map_time = round(time() - map_time)\n",
    "mAP = np.mean(APs)\n",
    "mAP_str = str(mAP).replace('.', ',')\n",
    "print(\"mAP: \", mAP_str)\n",
    "name = \"[{}_{}] Confusion Matrix\".format(NB_STEPS, NB_EPOCHS)\n",
    "name2 = \"[{}_{}] Normalized Confusion Matrix\".format(NB_STEPS, NB_EPOCHS)\n",
    "saveDir = 'logs/confusion_matrix/'\n",
    "cmap = plt.cm.get_cmap('hot')\n",
    "visualize.display_confusion_matrix(confusion_matrix, \n",
    "                                   dataset_val.get_class_names(), \n",
    "                                   title=name, cmap=cmap, show=False,\n",
    "                                   fileName=saveDir + name)\n",
    "visualize.display_confusion_matrix(confusion_matrix, \n",
    "                                   dataset_val.get_class_names(), \n",
    "                                   title=name2, cmap=cmap, show=False, \n",
    "                                   normalize=True, \n",
    "                                   fileName=saveDir + name2)\n",
    "with open(\"logs/auto_results.csv\", \"a\") as file:\n",
    "    file.write('\"{}\"; \"{}\"; \"{}\"; {}; {}; {}; {}\\n'.format(ctime(time()),\n",
    "                                                           init_with,\n",
    "                                                           weights_saved_file,\n",
    "                                                           NB_STEPS,\n",
    "                                                           NB_EPOCHS,\n",
    "                                                           training_time,\n",
    "                                                           mAP_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if TOAST:\n",
    "    m = ('0' if map_time // 60 < 10 else '') + str(map_time // 60)\n",
    "    s = ('0' if map_time % 60 < 10 else '') + str(map_time % 60)\n",
    "    toaster.show_toast(\"Mask R-CNN\",\n",
    "                       \"mAP computed : {:.3f}%\\nDuration : {}:{}\".format(mAP*100, m, s),\n",
    "                       icon_path=None,\n",
    "                       duration=30,\n",
    "                       threaded=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "celltoolbar": "Format de la Cellule Texte Brut",
  "colab": {
   "collapsed_sections": [
    "L7n2Ei9JJQXr"
   ],
   "name": "Test Updated Mask R-CNN cell nucleus.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
