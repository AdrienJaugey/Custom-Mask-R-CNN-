{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dto-uOuWSZIE"
   },
   "source": [
    "# [DEPRECATED] Updated Mask R-CNN (Matterport) - Train cell nucleus Dataset\n",
    "This is an updated version of [Mask R-CNN - Train cell nucleus Dataset](https://colab.research.google.com/github/navidyou/Mask-RCNN-implementation-for-cell-nucleus-detection-executable-on-google-colab-/blob/master/mask_RCNN_cell_nucleus_google_colab.ipynb) for Google Colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hy5xg58-3p-"
   },
   "source": [
    "## Initialisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the main variables to customize the training. Be sure to set the number of epoch you want along with the correct weights file to use as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to which epoch it should train\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "# To restart or continue training, set to last\n",
    "# If custom is choosed, please set custom_weights_file to true name of the file (should be in ./logs/ directory)\n",
    "init_with = \"base\" #@param [\"coco\", \"imagenet\", \"last\", \"base\", \"custom\"]\n",
    "custom_weights_file = \"mask_rcnn_nephrologie_XXXX_XXX.h5\"\n",
    "\n",
    "# Format of images in the dataset (if wrapper used, it should be png)\n",
    "IMAGE_FORMAT = 'jpg' #@param ['jp2', 'png', 'jpg', 'bmp']\n",
    "# Side size of a division\n",
    "DIVISION_SIZE = 1024\n",
    "\n",
    "# For main training, set cortexMode to false\n",
    "# Remaining of test about cortex detection, should be deleted or replaced\n",
    "cortexMode = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "EMwapxaFSZIH",
    "outputId": "6d7713da-1aa9-408a-fd55-b23e987f06a6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import os\n",
    "    import sys\n",
    "    import random\n",
    "    import math\n",
    "    import re\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import json\n",
    "    #import pandas as pd\n",
    "    from shlex import quote\n",
    "    from time import time, ctime\n",
    "    from common_utils import progressBar, formatTime\n",
    "\n",
    "    TOAST = True\n",
    "    if TOAST:\n",
    "        try:\n",
    "            from win10toast import ToastNotifier\n",
    "            toaster = ToastNotifier()\n",
    "        except ModuleNotFoundError:\n",
    "            TOAST = False\n",
    "\n",
    "    from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    classesInfo = [\n",
    "        {\"inferenceID\": 1,  \"id\": 0,  \"name\": \"cortex\",            \"color\": \"#ffaa00\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 2,  \"id\": 1,  \"name\": \"medullaire\",        \"color\": \"#ff0000\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 3,  \"id\": 2,  \"name\": \"fond\",              \"color\": \"#ffffff\", \"ignore\": not cortexMode},\n",
    "        {\"inferenceID\": 1,  \"id\": 3,  \"name\": \"tubule_sain\",       \"color\": \"#ff007f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 2,  \"id\": 4,  \"name\": \"tubule_atrophique\", \"color\": \"#55557f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 3,  \"id\": 5,  \"name\": \"nsg\",               \"color\": \"#55007f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 4,  \"id\": 6,  \"name\": \"nsg_complet\",       \"color\": \"#ff557f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 5,  \"id\": 7,  \"name\": \"nsg_partiel\",       \"color\": \"#55aa7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 6,  \"id\": 8,  \"name\": \"pac\",               \"color\": \"#ffaa7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 7,  \"id\": 9,  \"name\": \"veine\",             \"color\": \"#0000ff\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 8,  \"id\": 10, \"name\": \"vaisseau\",          \"color\": \"#55ff7f\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 9,  \"id\": 11, \"name\": \"intima\",            \"color\": \"#aa0000\", \"ignore\": cortexMode},\n",
    "        {\"inferenceID\": 10, \"id\": 12, \"name\": \"media\",             \"color\": \"#aa5500\", \"ignore\": cortexMode}\n",
    "    ]\n",
    "    \n",
    "    # Data Path\n",
    "    if cortexMode:\n",
    "        TRAIN_PATH = 'nephrology_cortex_dataset_train/'\n",
    "        MAP_PATH = 'nephrology_cortex_dataset_val/'\n",
    "    else:\n",
    "        TRAIN_PATH = 'nephrology_dataset_train/'\n",
    "        MAP_PATH = 'nephrology_dataset_val/'\n",
    "    # Get train and test IDs\n",
    "    train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "    map_ids = next(os.walk(MAP_PATH))[1]\n",
    "\n",
    "    NB_STEPS = len(train_ids)\n",
    "    \n",
    "    CUSTOM_CLASS_NAMES = []\n",
    "    for classInfo in classesInfo:\n",
    "        if not classInfo[\"ignore\"]:\n",
    "            CUSTOM_CLASS_NAMES.append(classInfo[\"name\"])\n",
    "    NB_CLASS = len(CUSTOM_CLASS_NAMES)\n",
    "    COLOR_PER_CLASS = True\n",
    "    evaluation_size = len(map_ids)\n",
    "    # evaluation_size = 30 #@param {type:\"slider\", min:10, max:65, step:1}\n",
    "\n",
    "\n",
    "    from mrcnn import config\n",
    "    from mrcnn import utils\n",
    "    from mrcnn import model\n",
    "    from mrcnn import visualize\n",
    "\n",
    "    from mrcnn.config import Config\n",
    "    from mrcnn import utils\n",
    "    from mrcnn import model as modellib\n",
    "    from mrcnn import visualize\n",
    "    from mrcnn.model import log\n",
    "\n",
    "    %matplotlib inline \n",
    "\n",
    "    # Root directory of the project\n",
    "    ROOT_DIR = os.getcwd()\n",
    "\n",
    "    # Directories to save logs and trained model\n",
    "    MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "    IMAGES_DIR = os.path.join(MODEL_DIR, \"images\")\n",
    "    CONF_MATRIX_DIR = os.path.join(MODEL_DIR, \"confusion_matrix\")\n",
    "    for path in [MODEL_DIR, IMAGES_DIR, CONF_MATRIX_DIR]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    RESULT_CSV_PATH = os.path.join(MODEL_DIR, \"auto_results.csv\")\n",
    "    if not os.path.exists(RESULT_CSV_PATH):\n",
    "        with open(RESULT_CSV_PATH, 'w') as csv:\n",
    "            csv.write(\"datetime; input_weights; output_weights; nb_steps; nb_epochs; duration; mAP\")\n",
    "\n",
    "    # Local path to trained weights file\n",
    "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "    # Download COCO trained weights from Releases if needed\n",
    "    if not os.path.exists(COCO_MODEL_PATH):\n",
    "        utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "    print(\"Cell done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpT9HgC7SZIN"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "colab_type": "code",
    "id": "jBONWUhASZIO",
    "outputId": "30b3f0fb-e933-4b7c-b6e8-1fa2898a117c"
   },
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"skinet\"\n",
    "\n",
    "    # Train on 1 GPU and 1 images per GPU. We can put multiple images on each\n",
    "    # GPU. Batch size is (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + NB_CLASS  # background + all classes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = DIVISION_SIZE\n",
    "    IMAGE_MAX_DIM = DIVISION_SIZE\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 64, 128, 256)  # anchor side in pixels\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 800\n",
    "\n",
    "    # set number of epoch\n",
    "    STEPS_PER_EPOCH = NB_STEPS // IMAGES_PER_GPU\n",
    "\n",
    "    # set validation steps\n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "\n",
    "config = CustomConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dhvNUELSZIS"
   },
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj3zh7wMSZIW"
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    #fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    #return ax\n",
    "    return plt.subplots(rows, cols, figsize=(size*cols, size*rows), frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjEu-7I1SZIY"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqkR3-OHSZIY"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_id, custom_class_names, dataset_path, enable_occlusions=True):\n",
    "        super().__init__()\n",
    "        self.__ID = dataset_id\n",
    "        self.__CUSTOM_CLASS_NAMES = custom_class_names.copy()\n",
    "        self.__PATH = os.path.normpath(dataset_path)\n",
    "        self.__ENABLE_OCCLUSIONS = enable_occlusions\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.__CUSTOM_CLASS_NAMES.copy()\n",
    "\n",
    "    def load_images(self):\n",
    "        # Add classes\n",
    "        for class_id, class_name in enumerate(self.__CUSTOM_CLASS_NAMES):\n",
    "            self.add_class(self.__ID, class_id + 1, class_name)\n",
    "\n",
    "        for id_ in os.listdir(self.__PATH):\n",
    "            img_path = os.path.join(self.__PATH, id_, \"images\")\n",
    "            img_path = os.path.join(img_path, os.listdir(img_path)[0])\n",
    "            self.add_image(self.__ID, image_id=id_, path=img_path)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        img = super().load_image(image_id)\n",
    "        img = resize(img, (config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]), mode='constant', preserve_range=True)\n",
    "        return img\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == self.__ID:\n",
    "            return info[self.__ID]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for cells of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        info = info.get(\"id\")\n",
    "\n",
    "        path = os.path.join(self.__PATH, info)\n",
    "\n",
    "        # Counting masks for current image\n",
    "        number_of_masks = 0\n",
    "        for masks_dir in os.listdir(path):\n",
    "            # For each directory excepting /images\n",
    "            if masks_dir not in self.__CUSTOM_CLASS_NAMES:\n",
    "                continue\n",
    "            masks_dir_path = os.path.join(path, masks_dir)\n",
    "            # Adding length of directory https://stackoverflow.com/questions/2632205/how-to-count-the-number-of-files-in-a-directory-using-python\n",
    "            number_of_masks += len([name_ for name_ in os.listdir(masks_dir_path) if os.path.isfile(os.path.join(masks_dir_path, name_))])\n",
    "\n",
    "        # Reading masks\n",
    "        masks = np.zeros([config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], number_of_masks], dtype=np.uint8)\n",
    "        classes = np.zeros((number_of_masks,), dtype=int)\n",
    "        idx = 0\n",
    "        for masks_dir in os.listdir(path):\n",
    "            if masks_dir not in self.__CUSTOM_CLASS_NAMES:\n",
    "                continue\n",
    "            temp_class_id = self.__CUSTOM_CLASS_NAMES.index(masks_dir) + 1\n",
    "            masks_dir_path = os.path.join(path, masks_dir)\n",
    "            for mask_file in os.listdir(masks_dir_path):\n",
    "                mask_ = imread(os.path.join(masks_dir_path, mask_file))\n",
    "                mask_ = resize(mask_, (config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]), mode='constant', preserve_range=True)\n",
    "                masks[:, :, idx] = mask_\n",
    "                classes[idx] = temp_class_id\n",
    "                idx += 1\n",
    "        # Handle occlusions\n",
    "        if self.__ENABLE_OCCLUSIONS:\n",
    "            occlusion = np.logical_not(masks[:, :, -1]).astype(np.uint8)\n",
    "            for i in range(number_of_masks - 2, -1, -1):\n",
    "                masks[:, :, i] = masks[:, :, i] * occlusion\n",
    "                occlusion = np.logical_and(occlusion, np.logical_not(masks[:, :, i]))\n",
    "        return masks, classes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAhNtW_TSZIb"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = CustomDataset(config.NAME, CUSTOM_CLASS_NAMES, TRAIN_PATH, enable_occlusions=False)\n",
    "dataset_train.load_images()\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CustomDataset(config.NAME, CUSTOM_CLASS_NAMES, MAP_PATH, enable_occlusions=False)\n",
    "dataset_val.load_images()\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "yAizzQC5SZIf",
    "outputId": "215f6df3-955f-4086-b531-df717e6f682b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyEQKAnMSZIi"
   },
   "source": [
    "## Ceate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GCYogpmSZIj",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUuC-fI4SZIl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    listDir = os.listdir(MODEL_DIR)\n",
    "    listDir.sort()\n",
    "    lastDir = ''\n",
    "    for logDir in listDir:\n",
    "        if os.path.isdir(os.path.join(MODEL_DIR, logDir)) and 'skinet20' in logDir:\n",
    "            lastDir = logDir\n",
    "    lastDirPath = os.path.join(MODEL_DIR, lastDir)\n",
    "    listDir = os.listdir(lastDirPath)\n",
    "    listDir.sort()\n",
    "    lastFile = ''\n",
    "    for logFile in listDir:\n",
    "        if '.h5' in logFile:\n",
    "            lastFile = logFile\n",
    "    if lastFile == '':\n",
    "        print(\"Last file not found, using base\")\n",
    "        init_with = \"base\"\n",
    "        weights_path = os.path.join(MODEL_DIR, 'mask_rcnn_base.h5')\n",
    "    else:\n",
    "        weights_path = os.path.join(lastDirPath, lastFile)\n",
    "        print(\"Last file is \" + weights_path)\n",
    "    model.load_weights(weights_path, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"base\":\n",
    "    weights_path = os.path.join(MODEL_DIR, 'mask_rcnn_base.h5')\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"custom\":\n",
    "    weights_path = os.path.join(MODEL_DIR, custom_weights_file)\n",
    "    print(\"Loading {} as weights file\".format(weights_path))\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzZuQxylSZIo"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0_mousFNZb9"
   },
   "source": [
    "### Starting to train\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN Training Tool\",\n",
    "                       f\"Starting training ({NB_STEPS} steps, {NB_EPOCHS} epochs)\",\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)\n",
    "start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "colab_type": "code",
    "id": "j2jmfqdLSZIp",
    "outputId": "615119d9-3b0f-45c0-b0e9-9cc64cca9e35",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=NB_EPOCHS, \n",
    "            layers='heads',\n",
    "            augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wN1l921SZIt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "# model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE / 10, epochs=2, layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "training_time = round(time() - start_time)\n",
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN Training Tool\",\n",
    "                       f\"Finish training ({NB_STEPS} steps, {NB_EPOCHS} epochs) in {formatTime(training_time)} (avg {formatTime(round(training_time / NB_EPOCHS))}\",\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRK53lnTSZIx",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "weights_saved_file = f\"mask_rcnn_nephrologie{'_cortex' if cortexMode else ''}_{NB_STEPS}_{NB_EPOCHS}.h5\"\n",
    "model_path = os.path.join(MODEL_DIR, weights_saved_file)\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldulTQXRSZI0"
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGXrGMjVDBOt"
   },
   "source": [
    "### Initialisation of the inference model and loading of weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWhUidKESZI1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(CustomConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWhUidKESZI1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "if model_path is None or not os.path.exists(model_path):\n",
    "    model_path = os.path.join(MODEL_DIR, weights_saved_file)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Aw-MI01DRdc"
   },
   "source": [
    "### Inference on random selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSldvjKYDq8j"
   },
   "source": [
    "Display of randomly chosen image with exepected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-aJVKAhSZI3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                                                                   image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "_ = visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, dataset_train.class_names, \n",
    "                                colorPerClass=COLOR_PER_CLASS, figsize=(16, 16), \n",
    "                                title=f\"{map_ids[image_id]} Expected\",\n",
    "                                fileName=f\"logs/images/[{NB_STEPS}_{NB_EPOCHS}] Expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgSVf-PuDyl7"
   },
   "source": [
    "Detection and display of the predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyAT1glESZI7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "fig_, ax_ = get_ax(size=16)\n",
    "_ = visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], dataset_val.class_names, \n",
    "                                r['scores'], colorPerClass=COLOR_PER_CLASS, figsize=(16, 16), ax=ax_, fig=fig_, \n",
    "                                title=f\"{map_ids[image_id]} Predicted\",\n",
    "                                fileName=f\"logs/images/[{NB_STEPS}_{NB_EPOCHS}] Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8mN9BsDSZI-"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr8rCnaXJa7Q"
   },
   "source": [
    "### Mean Average Precision (mAP) computation on a multiple-detection test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ib5pJXg3SZJA",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "#Running on 30 images by default. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, evaluation_size)\n",
    "image_ids = dataset_val.image_ids\n",
    "random.shuffle(image_ids)\n",
    "APs = []\n",
    "confusion_matrix = np.zeros((NB_CLASS + 1, NB_CLASS + 1), dtype=np.int32)\n",
    "map_time = time()\n",
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN Training Tool\",\n",
    "                       \"Starting mAP computation\",\n",
    "                       icon_path=None,\n",
    "                       duration=10,\n",
    "                       threaded=True)\n",
    "progressBar(0, len(image_ids), \"Computing mAP : \")\n",
    "for idx, image_id in enumerate(image_ids):\n",
    "    if TOAST and idx + 1 == evaluation_size // 2:\n",
    "        toaster.show_toast(\"Mask R-CNN Training Tool\", \"50% mAP computation achieved\",\n",
    "                           icon_path=None, duration=10, threaded=True)\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config, image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps, temp_confusion_matrix = \\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"],\n",
    "                             r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
    "                             nb_class=NB_CLASS, \n",
    "                             confusion_iou_threshold=0.1)\n",
    "    if idx + 1 == evaluation_size:\n",
    "        map_time = round(time() - map_time)\n",
    "    progressBar(idx + 1, evaluation_size, \"Computing mAP : \", suffix=f\" ({formatTime(map_time)})\")\n",
    "    APs.append(AP)\n",
    "    confusion_matrix = np.add(confusion_matrix, temp_confusion_matrix)\n",
    "\n",
    "mAP = np.mean(APs)\n",
    "mAP_str = str(mAP).replace('.', ',')\n",
    "print(f\"mAP: {mAP:06.2%}\")\n",
    "name = f\"[{NB_STEPS}_{NB_EPOCHS}] Confusion Matrix\"\n",
    "name2 = f\"[{NB_STEPS}_{NB_EPOCHS}] Normalized Confusion Matrix\"\n",
    "cmap = plt.cm.get_cmap('hot')\n",
    "visualize.display_confusion_matrix(confusion_matrix, \n",
    "                                   dataset_val.get_class_names(), \n",
    "                                   title=name, cmap=cmap, show=False,\n",
    "                                   fileName=os.path.join(CONF_MATRIX_DIR, name))\n",
    "visualize.display_confusion_matrix(confusion_matrix, \n",
    "                                   dataset_val.get_class_names(), \n",
    "                                   title=name2, cmap=cmap, show=False, \n",
    "                                   normalize=True, \n",
    "                                   fileName=os.path.join(CONF_MATRIX_DIR, name2))\n",
    "with open(RESULT_CSV_PATH, \"a\") as file:\n",
    "    file.write(f'\"{ctime(time())}\"; \"{init_with}\"; \"{weights_saved_file}\"; {NB_STEPS}; {NB_EPOCHS}; {training_time}; {mAP_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if TOAST:\n",
    "    toaster.show_toast(\"Mask R-CNN Training Tool\",\n",
    "                       f\"mAP computed : {mAP:06.2%}%\\nDuration : {formatTime(map_time)}\",\n",
    "                       icon_path=None,\n",
    "                       duration=30,\n",
    "                       threaded=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "celltoolbar": "Format de la Cellule Texte Brut",
  "colab": {
   "collapsed_sections": [
    "L7n2Ei9JJQXr"
   ],
   "name": "Test Updated Mask R-CNN cell nucleus.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
